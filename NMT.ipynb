{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dense_units = 5\n",
    "vocab_size = 100\n",
    "embedding_dim = 3\n",
    "max_length = 6      # no of timesteps\n",
    "gru_units = 10     # same for encoder and decoder, enc/dec size\n",
    "batch_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.Variable([\n",
    "                [1, 3, 4, 10, 54, 2], # eg: <start> this is a  bag <end>\n",
    "                [1, 30, 4, 10, 76, 2],   #eg: <start> he is a boy <end>\n",
    "                [1, 3, 4, 10, 34, 2] # eg: <start> this is a bird <end>\n",
    "                     ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: \n",
      "[[ 1  3  4 10 54  2]\n",
      " [ 1 30  4 10 76  2]\n",
      " [ 1  3  4 10 34  2]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inputs: \\n{inputs.numpy()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Shape: (3, 6)\n"
     ]
    }
   ],
   "source": [
    "# Input shape = (batch_size, max_length)\n",
    "print(f\"Input Shape: {inputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "x = enc_embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: \n",
      "[[[-0.00891199  0.02697823 -0.02869316]\n",
      "  [-0.01130106  0.01705582 -0.01922449]\n",
      "  [ 0.0285736   0.01118445 -0.04263396]\n",
      "  [ 0.00814123  0.02765713 -0.04640173]\n",
      "  [-0.0217955   0.04247181  0.02000103]\n",
      "  [ 0.04501773  0.04759785 -0.04773393]]\n",
      "\n",
      " [[-0.00891199  0.02697823 -0.02869316]\n",
      "  [-0.02386779  0.00910946 -0.00812159]\n",
      "  [ 0.0285736   0.01118445 -0.04263396]\n",
      "  [ 0.00814123  0.02765713 -0.04640173]\n",
      "  [-0.00733377 -0.00835412 -0.01835717]\n",
      "  [ 0.04501773  0.04759785 -0.04773393]]\n",
      "\n",
      " [[-0.00891199  0.02697823 -0.02869316]\n",
      "  [-0.01130106  0.01705582 -0.01922449]\n",
      "  [ 0.0285736   0.01118445 -0.04263396]\n",
      "  [ 0.00814123  0.02765713 -0.04640173]\n",
      "  [ 0.01415043  0.03779215  0.00729457]\n",
      "  [ 0.04501773  0.04759785 -0.04773393]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Embeddings: \\n{x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding Shape: (3, 6, 3)\n"
     ]
    }
   ],
   "source": [
    "# Embedding Shape = (batch_size, max_length, embedding_dim)\n",
    "print(f\"Embedding Shape: {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder GRU\n",
    "enc_gru = tf.keras.layers.GRU(gru_units,\n",
    "                               return_sequences=True,\n",
    "                               return_state=True,\n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_shape = (batch_size, max_length, hidden_size_encoder)\n",
    "enc_output, enc_hidden = enc_gru(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output of Encoder or Values: (3, 6, 10)\n",
      "State of Encoder: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Output of Encoder or Values: {enc_output.shape}\")\n",
    "print(f\"State of Encoder: {enc_hidden.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = enc_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query Shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "# Query shape = (batch_size, gru_units)\n",
    "query = enc_hidden\n",
    "print(f\"Query Shape: {query.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query with Time Axis Shape: (3, 1, 10)\n"
     ]
    }
   ],
   "source": [
    "# Query with time axis shape = (batch_size, 1, gru_units)\n",
    "query_with_time_axis = tf.expand_dims(query, 1)\n",
    "print(f\"Query with Time Axis Shape: {query_with_time_axis.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Attention Layers\n",
    "query_layer = tf.keras.layers.Dense(dense_units)\n",
    "value_layer = tf.keras.layers.Dense(dense_units)\n",
    "V = tf.keras.layers.Dense(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate Query Shape: (3, 1, 5)\n"
     ]
    }
   ],
   "source": [
    "# intermediate query shape = (batch_size, 1, dense_units)\n",
    "intermediate_query = query_layer(query_with_time_axis)\n",
    "print(f\"Intermediate Query Shape: {intermediate_query.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate Values Shape: (3, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "# intermediate values shape = (batch_size, max_length, dense_units)\n",
    "intermediate_values = value_layer(values)\n",
    "print(f\"Intermediate Values Shape: {intermediate_values.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without V layer: (3, 6, 5)\n"
     ]
    }
   ],
   "source": [
    "# without V shape = (batch_size, max_length, dense_units)\n",
    "without_v = tf.tanh(intermediate_query + intermediate_values)\n",
    "print(f\"Without V layer: {without_v.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score Shape: (3, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "# score shape = (batch_size, max_length, 1) #applying V\n",
    "score = V(tf.nn.tanh(\n",
    "    query_layer(query_with_time_axis) + value_layer(values)))\n",
    "print(f\"Score Shape: {score.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Weights Shape: (3, 6, 1)\n"
     ]
    }
   ],
   "source": [
    "attention_weights = tf.nn.softmax(score, axis=1)\n",
    "print(f\"Attention Weights Shape: {attention_weights.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Vector Shape: (3, 10)\n"
     ]
    }
   ],
   "source": [
    "context_vector = attention_weights * values\n",
    "context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "print(f\"Context Vector Shape: {context_vector.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Embedding\n",
    "dec_embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder GRU\n",
    "dec_gru = tf.keras.layers.GRU(gru_units,\n",
    "                               return_sequences=True,\n",
    "                               return_state=True,\n",
    "                               recurrent_initializer='glorot_uniform')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Fully Connected\n",
    "fc = tf.keras.layers.Dense(vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    " # loss object\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss Function\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder Inputs\n",
    "decoder_inputs = tf.Variable([\n",
    "    [1, 4, 2], #eg. <start> adfk <end>\n",
    "    [1, 40, 2], #eg. <start> rtrtt <end>\n",
    "    [1, 80, 2]  #eg. <start> jadskf <end>\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "Decoder Input Shape (3, 1)\n",
      "Decoder Embedding Shape: (3, 1, 3)\n",
      "After Context Vector Concatenation Shape: (3, 1, 13)\n",
      "Decoder GRU Output Shape: (3, 1, 10)\n",
      "Decoder GRU Output Shape Reshape: (3, 10)\n",
      "Fully Connected Output: (3, 100)\n",
      "tf.Tensor(4.6061683, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decoder Input Shape (3, 1)\n",
      "Decoder Embedding Shape: (3, 1, 3)\n",
      "After Context Vector Concatenation Shape: (3, 1, 13)\n",
      "Decoder GRU Output Shape: (3, 1, 10)\n",
      "Decoder GRU Output Shape Reshape: (3, 10)\n",
      "Fully Connected Output: (3, 100)\n",
      "tf.Tensor(4.6030946, shape=(), dtype=float32)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Decoder Input Shape (3, 1)\n",
      "Decoder Embedding Shape: (3, 1, 3)\n",
      "After Context Vector Concatenation Shape: (3, 1, 13)\n",
      "Decoder GRU Output Shape: (3, 1, 10)\n",
      "Decoder GRU Output Shape Reshape: (3, 10)\n",
      "Fully Connected Output: (3, 100)\n",
      "tf.Tensor(4.6090603, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    print(\"\\n\\n\\n\")\n",
    "    single_dec_input = tf.expand_dims(decoder_inputs[:, i], 1)\n",
    "    print(f\"Decoder Input Shape {single_dec_input.shape}\")\n",
    "    # y shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "    y = dec_embedding(single_dec_input)\n",
    "    print(f\"Decoder Embedding Shape: {y.shape}\")\n",
    "    # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "    y = tf.concat([tf.expand_dims(context_vector, 1), y], axis=-1)\n",
    "    print(f\"After Context Vector Concatenation Shape: {y.shape}\")\n",
    "    # passing the concatenated vector to the GRU\n",
    "    output, state = dec_gru(y)\n",
    "    print(f\"Decoder GRU Output Shape: {output.shape}\")\n",
    "    # output shape == (batch_size * 1, hidden_size)\n",
    "    output = tf.reshape(output, (-1, output.shape[2]))\n",
    "    print(f\"Decoder GRU Output Shape Reshape: {output.shape}\")\n",
    "    # output shape == (batch_size, vocab)\n",
    "    y = fc(output)\n",
    "    print(f\"Fully Connected Output: {y.shape}\")\n",
    "    # print(y)\n",
    "    loss = loss_function(real=decoder_inputs[:, i], pred=y)\n",
    "    print(loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}